{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc1288d2",
   "metadata": {},
   "source": [
    "# Эксперементальная часть"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91791992",
   "metadata": {},
   "source": [
    "Импортируем нужные бибилиотеки и создаем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1847fc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-26 16:22:20.417547: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-26 16:22:20.557961: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761484940.614603    1805 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1761484940.630771    1805 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1761484940.745062    1805 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1761484940.745090    1805 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1761484940.745091    1805 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1761484940.745092    1805 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-10-26 16:22:20.758966: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from uplift import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1ea117c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:34<00:00, 17.18s/it]\n"
     ]
    }
   ],
   "source": [
    "DATASETS = ['CO', 'CP']\n",
    "all_datasets = {}\n",
    "\n",
    "# Загрузка\n",
    "for name in tqdm(DATASETS):\n",
    "    train_df, vali_df, test_df, num_users, num_items, item_pop = get_dataset(name, path_to_data=\".\")\n",
    "    all_datasets[name] = {\n",
    "        \"train\": train_df,\n",
    "        \"vali\": vali_df,\n",
    "        \"test\": test_df,\n",
    "        \"num_users\": num_users,\n",
    "        \"num_items\": num_items,\n",
    "        \"item_popularity\": item_pop\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b53d646f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator()\n",
    "measures = ['CPrec_10', 'CPrec_100', 'CDCG', 'CDCG_100']\n",
    "propensity_values = []\n",
    "casual_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efd69531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([699215031, 227336022, 788646988, 316758339, 204176893])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_rng = np.random.default_rng(12345)\n",
    "seeds = base_rng.integers(low=0, high=10**9, size=5)\n",
    "seeds # для нескольких запусков модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578d1883",
   "metadata": {},
   "source": [
    "# Propensity модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c31ac849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "from scipy.stats import kendalltau\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy.stats import entropy\n",
    "\n",
    "def predict_z(df_train, df_val, epsilon=0.2):\n",
    "    p_train = df_train['pred'].values\n",
    "    norm_mean = float(p_train.mean())\n",
    "    norm_std = float(p_train.std())\n",
    "    \n",
    "    p_pred = df_val['pred'].values\n",
    "\n",
    "    p_norm = (p_pred - norm_mean) / norm_std\n",
    "    z_pred = (p_norm >= epsilon).astype(int)\n",
    "    return z_pred\n",
    "\n",
    "def get_propensity_metrics(df_train, df_val, epsilon=0.2):\n",
    "    \"\"\"\n",
    "    Оценка качества предсказания propensity scores:\n",
    "    - KLD между истинным p_true и предсказанным p_pred,\n",
    "    - Kendall’s Tau между ними,\n",
    "    - F1-score бинарной классификации exposure с порогом epsilon.\n",
    "    \"\"\"\n",
    "    p_pred = df_val['pred'].values\n",
    "    p_true = df_val['propensity'].values\n",
    "\n",
    "    z_true = df_val['treated'].values\n",
    "    z_pred = predict_z(df_train, df_val)\n",
    "    \n",
    "    p_pred = np.clip(p_pred, 1e-6, 1 - 1e-6)\n",
    "    p_true = np.clip(p_true, 1e-6, 1 - 1e-6)\n",
    "\n",
    "    kld = entropy(p_true, p_pred)\n",
    "    tau, _ = kendalltau(p_true, p_pred)\n",
    "    f1 = f1_score(z_true, z_pred)\n",
    "    \n",
    "    return {'kld': kld, 'tau': tau, 'f1': f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d823a9",
   "metadata": {},
   "source": [
    "## Эксперемент 4: Сравнение propensity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11633be",
   "metadata": {},
   "source": [
    "### RandomBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc19276",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kld': np.float64(0.9388043105934193), 'tau': np.float64(-4.950504606197425e-05), 'f1': 0.25671376334820256} {'kld': np.float64(0.9389020004862865), 'tau': np.float64(-4.950466794449602e-05), 'f1': 0.22717067309400815}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kld': np.float64(0.9387870600287442), 'tau': np.float64(5.87220945903375e-05), 'f1': 0.25667898471130174} {'kld': np.float64(0.9388898540169508), 'tau': np.float64(5.871660250145151e-05), 'f1': 0.22712122727225706}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kld': np.float64(0.9389031146702748), 'tau': np.float64(2.9589920423224123e-05), 'f1': 0.25664160135318903} {'kld': np.float64(0.9390040791634029), 'tau': np.float64(2.9594298416231692e-05), 'f1': 0.22708004017088007}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kld': np.float64(0.9387153215150433), 'tau': np.float64(7.455194184387505e-05), 'f1': 0.2566605327896183} {'kld': np.float64(0.9388156304024016), 'tau': np.float64(7.455516889625732e-05), 'f1': 0.22719794941985044}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset:  50%|█████     | 1/2 [02:23<02:23, 143.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kld': np.float64(0.9389650960397009), 'tau': np.float64(-3.7243651997708444e-06), 'f1': 0.25659775090099063} {'kld': np.float64(0.9390697701055551), 'tau': np.float64(-3.727443490870921e-06), 'f1': 0.22710148565506633}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kld': np.float64(1.4344408134140807), 'tau': np.float64(0.00012753967178804037), 'f1': 0.2566078024475753} {'kld': np.float64(1.434575851288269), 'tau': np.float64(0.00012753940522444788), 'f1': 0.22723907737257493}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kld': np.float64(1.4348942359913341), 'tau': np.float64(0.00021691150885053327), 'f1': 0.2566004598083176} {'kld': np.float64(1.4350319337030566), 'tau': np.float64(0.00021691145932085812), 'f1': 0.22711835954581422}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kld': np.float64(1.4352525374337914), 'tau': np.float64(-0.00014902701387134375), 'f1': 0.25660808357475406} {'kld': np.float64(1.4353932195455803), 'tau': np.float64(-0.00014902692526501702), 'f1': 0.22722141376210706}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kld': np.float64(1.4349788972088413), 'tau': np.float64(7.04801105489145e-05), 'f1': 0.2565524051108811} {'kld': np.float64(1.435104386265683), 'tau': np.float64(7.048020867551325e-05), 'f1': 0.2271084216873612}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset: 100%|██████████| 2/2 [04:35<00:00, 137.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kld': np.float64(1.4343482526790643), 'tau': np.float64(0.0001313931443565275), 'f1': 0.2566406220233451} {'kld': np.float64(1.4344891309701588), 'tau': np.float64(0.0001313927362532879), 'f1': 0.2271644426568644}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset in tqdm(DATASETS, desc=\"Dataset\", position=0):\n",
    "    for seed in tqdm(seeds, desc=f\"Runs on {dataset}\", position=1, leave=False):\n",
    "        model = RandomBase(all_datasets[dataset]['num_users'], all_datasets[dataset]['num_items'])\n",
    "        model_name = \"RandomBase\"\n",
    "\n",
    "        model.fit(all_datasets[dataset]['train'])\n",
    "\n",
    "        all_datasets[dataset]['test'][f\"{model_name}_pred\"] = model.predict(all_datasets[dataset]['test'])\n",
    "        all_datasets[dataset]['train'][f\"{model_name}_pred\"] = model.predict(all_datasets[dataset]['train'])\n",
    "\n",
    "        value = get_propensity_metrics(df_train=all_datasets[dataset]['train'].rename(columns={f\"{model_name}_pred\": \"pred\"}),\n",
    "                                        df_val=all_datasets[dataset]['test'].rename(columns={f\"{model_name}_pred\": \"pred\"}), epsilon=0.2)\n",
    "        value[\"model\"] = model_name\n",
    "        value[\"dataset\"] = dataset\n",
    "        propensity_values.append(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db9bc86",
   "metadata": {},
   "source": [
    "### PopularBase\n",
    "\n",
    "Запускаем только 1 раз так как, тут ничего не зависит от random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6cddcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:20<00:20, 20.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kld': np.float64(0.8702415033803848), 'tau': np.float64(0.24010317065025308), 'f1': 0.028714803511645785} {'kld': np.float64(0.8748721000699091), 'tau': np.float64(0.24010308228543284), 'f1': 0.26932261112792066}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:40<00:00, 20.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kld': np.float64(0.5410552712778826), 'tau': np.float64(0.7863079021412096), 'f1': 0.018896761914428236} {'kld': np.float64(0.5414550794410529), 'tau': np.float64(0.7863079021412096), 'f1': 0.5588533544179842}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset in tqdm(DATASETS):\n",
    "    model = PopularBase(all_datasets[dataset]['num_users'], all_datasets[dataset]['num_items'])\n",
    "    model_name = \"PopularBase\"\n",
    "\n",
    "    model.fit(all_datasets[dataset]['train'])\n",
    "\n",
    "    all_datasets[dataset]['test'][f\"{model_name}_pred\"] = model.predict(all_datasets[dataset]['test'])\n",
    "    all_datasets[dataset]['train'][f\"{model_name}_pred\"] = model.predict(all_datasets[dataset]['train'])\n",
    "\n",
    "    value = get_propensity_metrics(df_train=all_datasets[dataset]['train'].rename(columns={f\"{model_name}_pred\": \"pred\"}),\n",
    "                                    df_val=all_datasets[dataset]['test'].rename(columns={f\"{model_name}_pred\": \"pred\"}), epsilon=0.2)\n",
    "    value[\"model\"] = model_name\n",
    "    value[\"dataset\"] = dataset\n",
    "    propensity_values.append(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96f2ac5",
   "metadata": {},
   "source": [
    "### PropCare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7db7db5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Runs on CO: 100%|██████████| 5/5 [02:12<00:00, 26.54s/it]\n",
      "Runs on CP: 100%|██████████| 5/5 [02:09<00:00, 25.92s/it]\n",
      "Datasets: 100%|██████████| 2/2 [04:22<00:00, 131.17s/it]\n"
     ]
    }
   ],
   "source": [
    "for dataset in tqdm(DATASETS, desc=\"Datasets\", position=0):\n",
    "    for i in tqdm(range(len(seeds)), desc=f\"Runs on {dataset}\", position=1):\n",
    "        model = PropCare.load_model(dir_path=f\"saved_models/propcare/best_{dataset}\", model_name=f\"model_{i+1}\", device='cuda')\n",
    "        model_name = \"PropCare\"\n",
    "\n",
    "        all_datasets[dataset]['test'][f\"{model_name}_pred\"] = model.predict(all_datasets[dataset]['test'])\n",
    "\n",
    "        value = model.get_metrics(all_datasets[dataset]['test'].rename(columns={f\"{model_name}_pred\": \"pred\"}))\n",
    "        value[\"model\"] = model_name\n",
    "        value[\"dataset\"] = dataset\n",
    "        propensity_values.append(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9304413c",
   "metadata": {},
   "source": [
    "### Итоги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "494749a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>kld_mean</th>\n",
       "      <th>kld_std</th>\n",
       "      <th>tau_mean</th>\n",
       "      <th>tau_std</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PopularBase</td>\n",
       "      <td>CO</td>\n",
       "      <td>0.874872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.269323</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PopularBase</td>\n",
       "      <td>CP</td>\n",
       "      <td>0.541455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.786308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.558853</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PropCare</td>\n",
       "      <td>CO</td>\n",
       "      <td>0.905728</td>\n",
       "      <td>0.011356</td>\n",
       "      <td>0.175620</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.388406</td>\n",
       "      <td>0.001946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PropCare</td>\n",
       "      <td>CP</td>\n",
       "      <td>0.900241</td>\n",
       "      <td>0.024333</td>\n",
       "      <td>0.431493</td>\n",
       "      <td>0.017465</td>\n",
       "      <td>0.547325</td>\n",
       "      <td>0.003251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomBase</td>\n",
       "      <td>CO</td>\n",
       "      <td>0.938936</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.227134</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomBase</td>\n",
       "      <td>CP</td>\n",
       "      <td>1.434919</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.227170</td>\n",
       "      <td>0.000053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model dataset  kld_mean   kld_std  tau_mean   tau_std   f1_mean  \\\n",
       "0  PopularBase      CO  0.874872  0.000000  0.240103  0.000000  0.269323   \n",
       "1  PopularBase      CP  0.541455  0.000000  0.786308  0.000000  0.558853   \n",
       "2     PropCare      CO  0.905728  0.011356  0.175620  0.005700  0.388406   \n",
       "3     PropCare      CP  0.900241  0.024333  0.431493  0.017465  0.547325   \n",
       "4   RandomBase      CO  0.938936  0.000090  0.000022  0.000045  0.227134   \n",
       "5   RandomBase      CP  1.434919  0.000339  0.000079  0.000123  0.227170   \n",
       "\n",
       "     f1_std  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.001946  \n",
       "3  0.003251  \n",
       "4  0.000044  \n",
       "5  0.000053  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = (\n",
    "    pd.DataFrame(propensity_values)\n",
    "    .groupby(['model', 'dataset'])\n",
    "    .agg(\n",
    "        kld_mean=('kld', 'mean'),\n",
    "        kld_std=('kld', lambda x: np.std(x, ddof=0)),\n",
    "        tau_mean=('tau', 'mean'),\n",
    "        tau_std=('tau', lambda x: np.std(x, ddof=0)),\n",
    "        f1_mean=('f1', 'mean'),\n",
    "        f1_std=('f1', lambda x: np.std(x, ddof=0)),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32976a8",
   "metadata": {},
   "source": [
    "## Эксперемент 6: оценка casual на основе DLCE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff5a67a",
   "metadata": {},
   "source": [
    "### Groynd-Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39c2edab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset: 100%|██████████| 2/2 [01:51<00:00, 55.76s/it]\n"
     ]
    }
   ],
   "source": [
    "for dataset in tqdm(DATASETS, desc=\"Dataset\", position=0):\n",
    "    for i in tqdm(range(len(seeds)), desc=f\"Runs on {dataset}\", position=1, leave=False):\n",
    "        model_name = \"DLCE_original\"\n",
    "        model = DLCE.load_model(dir_path=f\"saved_models/dlce/best_{dataset}\", model_name=f\"model_{i+1}\", device='cuda')\n",
    "\n",
    "        all_datasets[dataset]['test'][f\"{model_name}_pred\"] = model.predict(all_datasets[dataset]['test'])\n",
    "\n",
    "        value = evaluator.evaluate(all_datasets[dataset]['test'].rename(columns={f\"{model_name}_pred\": \"pred\"}), measures=measures)\n",
    "        value[\"model\"] = model_name\n",
    "        value[\"dataset\"] = dataset\n",
    "        casual_values.append(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f2bbc2",
   "metadata": {},
   "source": [
    "### Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb849766",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset: 100%|██████████| 2/2 [01:52<00:00, 56.16s/it]\n"
     ]
    }
   ],
   "source": [
    "for dataset in tqdm(DATASETS, desc=\"Dataset\", position=0):\n",
    "    for i in tqdm(range(len(seeds)), desc=f\"Runs on {dataset}\", position=1, leave=False):\n",
    "        model_name = \"DLCE_random\"\n",
    "        model = DLCE.load_model(dir_path=f\"saved_models/dlce/best_random_{dataset}\", model_name=f\"model_{i+1}\", device='cuda')\n",
    "\n",
    "        all_datasets[dataset]['test'][f\"{model_name}_pred\"] = model.predict(all_datasets[dataset]['test'])\n",
    "\n",
    "        value = evaluator.evaluate(all_datasets[dataset]['test'].rename(columns={f\"{model_name}_pred\": \"pred\"}), measures=measures)\n",
    "        value[\"model\"] = model_name\n",
    "        value[\"dataset\"] = dataset\n",
    "        casual_values.append(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6942165d",
   "metadata": {},
   "source": [
    "### Popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58d01f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset: 100%|██████████| 2/2 [01:52<00:00, 56.38s/it]\n"
     ]
    }
   ],
   "source": [
    "for dataset in tqdm(DATASETS, desc=\"Dataset\", position=0):\n",
    "    for i in tqdm(range(len(seeds)), desc=f\"Runs on {dataset}\", position=1, leave=False):\n",
    "        model_name = \"DLCE_popular\"\n",
    "        model = DLCE.load_model(dir_path=f\"saved_models/dlce/best_popular_{dataset}\", model_name=f\"model_{i+1}\", device='cuda')\n",
    "\n",
    "        all_datasets[dataset]['test'][f\"{model_name}_pred\"] = model.predict(all_datasets[dataset]['test'])\n",
    "\n",
    "        value = evaluator.evaluate(all_datasets[dataset]['test'].rename(columns={f\"{model_name}_pred\": \"pred\"}), measures=measures)\n",
    "        value[\"model\"] = model_name\n",
    "        value[\"dataset\"] = dataset\n",
    "        casual_values.append(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec7403c",
   "metadata": {},
   "source": [
    "### PropCare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "655e6f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset: 100%|██████████| 2/2 [01:50<00:00, 55.09s/it]\n"
     ]
    }
   ],
   "source": [
    "for dataset in tqdm(DATASETS, desc=\"Dataset\", position=0):\n",
    "    for i in tqdm(range(len(seeds)), desc=f\"Runs on {dataset}\", position=1, leave=False):\n",
    "        model_name = \"DLCE_propcare\"\n",
    "        model = DLCE.load_model(dir_path=f\"saved_models/dlce/best_propcare_{dataset}\", model_name=f\"model_{i+1}\", device='cuda')\n",
    "\n",
    "        all_datasets[dataset]['test'][f\"{model_name}_pred\"] = model.predict(all_datasets[dataset]['test'])\n",
    "\n",
    "        value = evaluator.evaluate(all_datasets[dataset]['test'].rename(columns={f\"{model_name}_pred\": \"pred\"}), measures=measures)\n",
    "        value[\"model\"] = model_name\n",
    "        value[\"dataset\"] = dataset\n",
    "        casual_values.append(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b72096",
   "metadata": {},
   "source": [
    "## Итого"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ed47c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>CPrec_10_mean</th>\n",
       "      <th>CPrec_100_mean</th>\n",
       "      <th>CDCG_mean</th>\n",
       "      <th>CDCG_100_mean</th>\n",
       "      <th>CPrec_10_std</th>\n",
       "      <th>CPrec_100_std</th>\n",
       "      <th>CDCG_std</th>\n",
       "      <th>CDCG_100_std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">DLCE_original</th>\n",
       "      <th>CO</th>\n",
       "      <td>0.171910</td>\n",
       "      <td>0.077625</td>\n",
       "      <td>6.793327</td>\n",
       "      <td>1.947316</td>\n",
       "      <td>0.001732</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.007517</td>\n",
       "      <td>0.008403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CP</th>\n",
       "      <td>0.088003</td>\n",
       "      <td>0.088506</td>\n",
       "      <td>7.283449</td>\n",
       "      <td>1.878666</td>\n",
       "      <td>0.003854</td>\n",
       "      <td>0.001407</td>\n",
       "      <td>0.013677</td>\n",
       "      <td>0.029609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">DLCE_popular</th>\n",
       "      <th>CO</th>\n",
       "      <td>0.021758</td>\n",
       "      <td>0.020282</td>\n",
       "      <td>5.645130</td>\n",
       "      <td>0.433364</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.008055</td>\n",
       "      <td>0.009565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CP</th>\n",
       "      <td>0.189684</td>\n",
       "      <td>0.085453</td>\n",
       "      <td>6.840123</td>\n",
       "      <td>2.134262</td>\n",
       "      <td>0.001933</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>0.010562</td>\n",
       "      <td>0.016759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">DLCE_propcare</th>\n",
       "      <th>CO</th>\n",
       "      <td>0.018787</td>\n",
       "      <td>0.015847</td>\n",
       "      <td>5.622955</td>\n",
       "      <td>0.337625</td>\n",
       "      <td>0.003177</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.009180</td>\n",
       "      <td>0.013266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CP</th>\n",
       "      <td>0.154595</td>\n",
       "      <td>0.084997</td>\n",
       "      <td>6.938097</td>\n",
       "      <td>2.013790</td>\n",
       "      <td>0.004903</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.019130</td>\n",
       "      <td>0.028583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">DLCE_random</th>\n",
       "      <th>CO</th>\n",
       "      <td>0.004677</td>\n",
       "      <td>0.009848</td>\n",
       "      <td>5.291087</td>\n",
       "      <td>0.190301</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.011475</td>\n",
       "      <td>0.018641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CP</th>\n",
       "      <td>0.033625</td>\n",
       "      <td>0.024632</td>\n",
       "      <td>5.297132</td>\n",
       "      <td>0.553320</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.010897</td>\n",
       "      <td>0.015807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       CPrec_10_mean  CPrec_100_mean  CDCG_mean  \\\n",
       "model         dataset                                             \n",
       "DLCE_original CO            0.171910        0.077625   6.793327   \n",
       "              CP            0.088003        0.088506   7.283449   \n",
       "DLCE_popular  CO            0.021758        0.020282   5.645130   \n",
       "              CP            0.189684        0.085453   6.840123   \n",
       "DLCE_propcare CO            0.018787        0.015847   5.622955   \n",
       "              CP            0.154595        0.084997   6.938097   \n",
       "DLCE_random   CO            0.004677        0.009848   5.291087   \n",
       "              CP            0.033625        0.024632   5.297132   \n",
       "\n",
       "                       CDCG_100_mean  CPrec_10_std  CPrec_100_std  CDCG_std  \\\n",
       "model         dataset                                                         \n",
       "DLCE_original CO            1.947316      0.001732       0.000402  0.007517   \n",
       "              CP            1.878666      0.003854       0.001407  0.013677   \n",
       "DLCE_popular  CO            0.433364      0.001159       0.000307  0.008055   \n",
       "              CP            2.134262      0.001933       0.000849  0.010562   \n",
       "DLCE_propcare CO            0.337625      0.003177       0.000639  0.009180   \n",
       "              CP            2.013790      0.004903       0.000981  0.019130   \n",
       "DLCE_random   CO            0.190301      0.001285       0.001067  0.011475   \n",
       "              CP            0.553320      0.001795       0.000601  0.010897   \n",
       "\n",
       "                       CDCG_100_std  \n",
       "model         dataset                \n",
       "DLCE_original CO           0.008403  \n",
       "              CP           0.029609  \n",
       "DLCE_popular  CO           0.009565  \n",
       "              CP           0.016759  \n",
       "DLCE_propcare CO           0.013266  \n",
       "              CP           0.028583  \n",
       "DLCE_random   CO           0.018641  \n",
       "              CP           0.015807  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_dict = {\n",
    "    f\"{m}_mean\": (m, \"mean\") for m in measures\n",
    "} | {\n",
    "    f\"{m}_std\": (m, lambda x: np.std(x, ddof=0)) for m in measures\n",
    "}\n",
    "\n",
    "summary = (\n",
    "    pd.DataFrame(casual_values)\n",
    "    .groupby(['model', 'dataset'])\n",
    "    .agg(**agg_dict)\n",
    ")\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5ba4d3",
   "metadata": {},
   "source": [
    "# Casual модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445f37e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"all_datasets.pkl\", \"rb\") as f:\n",
    "    all_datasets = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311439d1",
   "metadata": {},
   "source": [
    "## RandomBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a34cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset: 100%|██████████| 2/2 [03:26<00:00, 103.48s/it]\n"
     ]
    }
   ],
   "source": [
    "casual_values = []\n",
    "for dataset in tqdm(DATASETS, desc=\"Dataset\", position=0):\n",
    "    for i in tqdm(range(len(seeds)), desc=f\"Runs on {dataset}\", position=1, leave=False):\n",
    "        model_name = \"RandomBase\"\n",
    "\n",
    "        value = evaluator.evaluate(all_datasets[dataset]['test'].rename(columns={f\"{model_name}_pred\": \"pred\"}), measures=measures)\n",
    "        value[\"model\"] = model_name\n",
    "        value[\"dataset\"] = dataset\n",
    "        casual_values.append(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daa7bcd",
   "metadata": {},
   "source": [
    "## PopularBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "104d3845",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset: 100%|██████████| 2/2 [00:56<00:00, 28.21s/it]\n"
     ]
    }
   ],
   "source": [
    "for dataset in tqdm(DATASETS, desc=\"Dataset\", position=0):\n",
    "    for i in tqdm(range(len(seeds)), desc=f\"Runs on {dataset}\", position=1, leave=False):\n",
    "        model_name = \"PopularBase\"\n",
    "\n",
    "        value = evaluator.evaluate(all_datasets[dataset]['test'].rename(columns={f\"{model_name}_pred\": \"pred\"}), measures=measures)\n",
    "        value[\"model\"] = model_name\n",
    "        value[\"dataset\"] = dataset\n",
    "        casual_values.append(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbdb5d4",
   "metadata": {},
   "source": [
    "## DLCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60525697",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset: 100%|██████████| 2/2 [01:52<00:00, 56.04s/it]\n"
     ]
    }
   ],
   "source": [
    "for dataset in tqdm(DATASETS, desc=\"Dataset\", position=0):\n",
    "    for i in tqdm(range(len(seeds)), desc=f\"Runs on {dataset}\", position=1, leave=False):\n",
    "        model_name = \"DLCE_original\"\n",
    "        model = DLCE.load_model(dir_path=f\"saved_models/dlce/best_{dataset}\", model_name=f\"model_{i+1}\", device='cuda')\n",
    "\n",
    "        all_datasets[dataset]['test'][f\"{model_name}_pred\"] = model.predict(all_datasets[dataset]['test'])\n",
    "\n",
    "        value = evaluator.evaluate(all_datasets[dataset]['test'].rename(columns={f\"{model_name}_pred\": \"pred\"}), measures=measures)\n",
    "        value[\"model\"] = model_name\n",
    "        value[\"dataset\"] = dataset\n",
    "        casual_values.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "45d39595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>CPrec_10_mean</th>\n",
       "      <th>CPrec_100_mean</th>\n",
       "      <th>CDCG_mean</th>\n",
       "      <th>CDCG_100_mean</th>\n",
       "      <th>CPrec_10_std</th>\n",
       "      <th>CPrec_100_std</th>\n",
       "      <th>CDCG_std</th>\n",
       "      <th>CDCG_100_std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">DLCE_original</th>\n",
       "      <th>CO</th>\n",
       "      <td>0.171910</td>\n",
       "      <td>0.077625</td>\n",
       "      <td>6.793327</td>\n",
       "      <td>1.947316</td>\n",
       "      <td>0.001732</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.007517</td>\n",
       "      <td>0.008403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CP</th>\n",
       "      <td>0.088003</td>\n",
       "      <td>0.088506</td>\n",
       "      <td>7.283449</td>\n",
       "      <td>1.878666</td>\n",
       "      <td>0.003854</td>\n",
       "      <td>0.001407</td>\n",
       "      <td>0.013677</td>\n",
       "      <td>0.029609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">PopularBase</th>\n",
       "      <th>CO</th>\n",
       "      <td>0.053443</td>\n",
       "      <td>0.023746</td>\n",
       "      <td>5.825522</td>\n",
       "      <td>0.582403</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CP</th>\n",
       "      <td>0.054482</td>\n",
       "      <td>0.040598</td>\n",
       "      <td>6.098322</td>\n",
       "      <td>0.868866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">RandomBase</th>\n",
       "      <th>CO</th>\n",
       "      <td>0.003673</td>\n",
       "      <td>0.004271</td>\n",
       "      <td>5.017716</td>\n",
       "      <td>0.087671</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>0.005336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CP</th>\n",
       "      <td>0.004158</td>\n",
       "      <td>0.004353</td>\n",
       "      <td>4.942555</td>\n",
       "      <td>0.090615</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.002113</td>\n",
       "      <td>0.005025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       CPrec_10_mean  CPrec_100_mean  CDCG_mean  \\\n",
       "model         dataset                                             \n",
       "DLCE_original CO            0.171910        0.077625   6.793327   \n",
       "              CP            0.088003        0.088506   7.283449   \n",
       "PopularBase   CO            0.053443        0.023746   5.825522   \n",
       "              CP            0.054482        0.040598   6.098322   \n",
       "RandomBase    CO            0.003673        0.004271   5.017716   \n",
       "              CP            0.004158        0.004353   4.942555   \n",
       "\n",
       "                       CDCG_100_mean  CPrec_10_std  CPrec_100_std  CDCG_std  \\\n",
       "model         dataset                                                         \n",
       "DLCE_original CO            1.947316      0.001732       0.000402  0.007517   \n",
       "              CP            1.878666      0.003854       0.001407  0.013677   \n",
       "PopularBase   CO            0.582403      0.000000       0.000000  0.000000   \n",
       "              CP            0.868866      0.000000       0.000000  0.000000   \n",
       "RandomBase    CO            0.087671      0.000439       0.000250  0.001886   \n",
       "              CP            0.090615      0.000744       0.000242  0.002113   \n",
       "\n",
       "                       CDCG_100_std  \n",
       "model         dataset                \n",
       "DLCE_original CO           0.008403  \n",
       "              CP           0.029609  \n",
       "PopularBase   CO           0.000000  \n",
       "              CP           0.000000  \n",
       "RandomBase    CO           0.005336  \n",
       "              CP           0.005025  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_dict = {\n",
    "    f\"{m}_mean\": (m, \"mean\") for m in measures\n",
    "} | {\n",
    "    f\"{m}_std\": (m, lambda x: np.std(x, ddof=0)) for m in measures\n",
    "}\n",
    "\n",
    "summary = (\n",
    "    pd.DataFrame(casual_values)\n",
    "    .groupby(['model', 'dataset'])\n",
    "    .agg(**agg_dict)\n",
    ")\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40966cd0",
   "metadata": {},
   "source": [
    "# Различные моды DLCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d246b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset: 100%|██████████| 2/2 [01:52<00:00, 56.49s/it]\n",
      "Dataset: 100%|██████████| 2/2 [01:58<00:00, 59.37s/it]\n",
      "Dataset: 100%|██████████| 2/2 [01:55<00:00, 57.66s/it]\n",
      "Dataset: 100%|██████████| 2/2 [01:57<00:00, 58.56s/it]\n",
      "Dataset: 100%|██████████| 2/2 [02:02<00:00, 61.39s/it]\n",
      "Dataset: 100%|██████████| 2/2 [02:00<00:00, 60.16s/it]\n"
     ]
    }
   ],
   "source": [
    "for dlto_mode in [True, False]:\n",
    "    for tau_mode in ['ips', 'cips', 'naive']:\n",
    "        for dataset in tqdm(DATASETS, desc=\"Dataset\", position=0):\n",
    "            for i in tqdm(range(len(seeds)), desc=f\"Runs on {dataset}\", position=1, leave=False):\n",
    "                model_name = f\"DLCE_{dlto_mode}_{tau_mode}\"\n",
    "                model = DLCE.load_model(dir_path=f\"saved_models/dlce/modes/dlto{dlto_mode}_{tau_mode}_{dataset}\", model_name=f\"model_{i+1}\", device='cuda')\n",
    "\n",
    "                all_datasets[dataset]['test'][f\"{model_name}_pred\"] = model.predict(all_datasets[dataset]['test'])\n",
    "\n",
    "                value = evaluator.evaluate(all_datasets[dataset]['test'].rename(columns={f\"{model_name}_pred\": \"pred\"}), measures=measures)\n",
    "                value[\"model\"] = model_name\n",
    "                value[\"dataset\"] = dataset\n",
    "                casual_values.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f27c803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>CPrec_10_mean</th>\n",
       "      <th>CPrec_100_mean</th>\n",
       "      <th>CDCG_mean</th>\n",
       "      <th>CDCG_100_mean</th>\n",
       "      <th>CPrec_10_std</th>\n",
       "      <th>CPrec_100_std</th>\n",
       "      <th>CDCG_std</th>\n",
       "      <th>CDCG_100_std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">DLCE_False_cips</th>\n",
       "      <th>CO</th>\n",
       "      <td>0.171728</td>\n",
       "      <td>0.077582</td>\n",
       "      <td>6.792906</td>\n",
       "      <td>1.946146</td>\n",
       "      <td>1.884684e-03</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.007859</td>\n",
       "      <td>0.008793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CP</th>\n",
       "      <td>0.088367</td>\n",
       "      <td>0.088550</td>\n",
       "      <td>7.284219</td>\n",
       "      <td>1.879309</td>\n",
       "      <td>3.233122e-03</td>\n",
       "      <td>0.001313</td>\n",
       "      <td>0.014890</td>\n",
       "      <td>0.029840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">DLCE_False_ips</th>\n",
       "      <th>CO</th>\n",
       "      <td>0.171910</td>\n",
       "      <td>0.077625</td>\n",
       "      <td>6.793327</td>\n",
       "      <td>1.947316</td>\n",
       "      <td>1.732265e-03</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.007517</td>\n",
       "      <td>0.008403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CP</th>\n",
       "      <td>0.088003</td>\n",
       "      <td>0.088506</td>\n",
       "      <td>7.283449</td>\n",
       "      <td>1.878666</td>\n",
       "      <td>3.853558e-03</td>\n",
       "      <td>0.001407</td>\n",
       "      <td>0.013677</td>\n",
       "      <td>0.029609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">DLCE_False_naive</th>\n",
       "      <th>CO</th>\n",
       "      <td>0.057514</td>\n",
       "      <td>0.016896</td>\n",
       "      <td>5.489560</td>\n",
       "      <td>0.464600</td>\n",
       "      <td>6.938894e-18</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.002463</td>\n",
       "      <td>0.002915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CP</th>\n",
       "      <td>0.109589</td>\n",
       "      <td>0.074968</td>\n",
       "      <td>7.097955</td>\n",
       "      <td>1.681115</td>\n",
       "      <td>6.391744e-03</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.020650</td>\n",
       "      <td>0.029546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">DLCE_True_cips</th>\n",
       "      <th>CO</th>\n",
       "      <td>0.148298</td>\n",
       "      <td>0.070106</td>\n",
       "      <td>6.745000</td>\n",
       "      <td>1.728709</td>\n",
       "      <td>2.634570e-03</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.009815</td>\n",
       "      <td>0.015481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CP</th>\n",
       "      <td>0.103898</td>\n",
       "      <td>0.097103</td>\n",
       "      <td>7.294305</td>\n",
       "      <td>2.098142</td>\n",
       "      <td>4.790822e-03</td>\n",
       "      <td>0.002264</td>\n",
       "      <td>0.009118</td>\n",
       "      <td>0.032013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">DLCE_True_ips</th>\n",
       "      <th>CO</th>\n",
       "      <td>0.147934</td>\n",
       "      <td>0.070192</td>\n",
       "      <td>6.743509</td>\n",
       "      <td>1.728789</td>\n",
       "      <td>2.980123e-03</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.010707</td>\n",
       "      <td>0.014443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CP</th>\n",
       "      <td>0.103898</td>\n",
       "      <td>0.097103</td>\n",
       "      <td>7.294305</td>\n",
       "      <td>2.098142</td>\n",
       "      <td>4.790822e-03</td>\n",
       "      <td>0.002264</td>\n",
       "      <td>0.009118</td>\n",
       "      <td>0.032013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">DLCE_True_naive</th>\n",
       "      <th>CO</th>\n",
       "      <td>0.053443</td>\n",
       "      <td>0.025827</td>\n",
       "      <td>5.878835</td>\n",
       "      <td>0.660594</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.019477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CP</th>\n",
       "      <td>0.090585</td>\n",
       "      <td>0.064259</td>\n",
       "      <td>6.786157</td>\n",
       "      <td>1.447456</td>\n",
       "      <td>7.923525e-03</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>0.020451</td>\n",
       "      <td>0.037564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          CPrec_10_mean  CPrec_100_mean  CDCG_mean  \\\n",
       "model            dataset                                             \n",
       "DLCE_False_cips  CO            0.171728        0.077582   6.792906   \n",
       "                 CP            0.088367        0.088550   7.284219   \n",
       "DLCE_False_ips   CO            0.171910        0.077625   6.793327   \n",
       "                 CP            0.088003        0.088506   7.283449   \n",
       "DLCE_False_naive CO            0.057514        0.016896   5.489560   \n",
       "                 CP            0.109589        0.074968   7.097955   \n",
       "DLCE_True_cips   CO            0.148298        0.070106   6.745000   \n",
       "                 CP            0.103898        0.097103   7.294305   \n",
       "DLCE_True_ips    CO            0.147934        0.070192   6.743509   \n",
       "                 CP            0.103898        0.097103   7.294305   \n",
       "DLCE_True_naive  CO            0.053443        0.025827   5.878835   \n",
       "                 CP            0.090585        0.064259   6.786157   \n",
       "\n",
       "                          CDCG_100_mean  CPrec_10_std  CPrec_100_std  \\\n",
       "model            dataset                                               \n",
       "DLCE_False_cips  CO            1.946146  1.884684e-03       0.000441   \n",
       "                 CP            1.879309  3.233122e-03       0.001313   \n",
       "DLCE_False_ips   CO            1.947316  1.732265e-03       0.000402   \n",
       "                 CP            1.878666  3.853558e-03       0.001407   \n",
       "DLCE_False_naive CO            0.464600  6.938894e-18       0.000130   \n",
       "                 CP            1.681115  6.391744e-03       0.000869   \n",
       "DLCE_True_cips   CO            1.728709  2.634570e-03       0.000555   \n",
       "                 CP            2.098142  4.790822e-03       0.002264   \n",
       "DLCE_True_ips    CO            1.728789  2.980123e-03       0.000464   \n",
       "                 CP            2.098142  4.790822e-03       0.002264   \n",
       "DLCE_True_naive  CO            0.660594  0.000000e+00       0.001079   \n",
       "                 CP            1.447456  7.923525e-03       0.001130   \n",
       "\n",
       "                          CDCG_std  CDCG_100_std  \n",
       "model            dataset                          \n",
       "DLCE_False_cips  CO       0.007859      0.008793  \n",
       "                 CP       0.014890      0.029840  \n",
       "DLCE_False_ips   CO       0.007517      0.008403  \n",
       "                 CP       0.013677      0.029609  \n",
       "DLCE_False_naive CO       0.002463      0.002915  \n",
       "                 CP       0.020650      0.029546  \n",
       "DLCE_True_cips   CO       0.009815      0.015481  \n",
       "                 CP       0.009118      0.032013  \n",
       "DLCE_True_ips    CO       0.010707      0.014443  \n",
       "                 CP       0.009118      0.032013  \n",
       "DLCE_True_naive  CO       0.007962      0.019477  \n",
       "                 CP       0.020451      0.037564  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_dict = {\n",
    "    f\"{m}_mean\": (m, \"mean\") for m in measures\n",
    "} | {\n",
    "    f\"{m}_std\": (m, lambda x: np.std(x, ddof=0)) for m in measures\n",
    "}\n",
    "\n",
    "summary = (\n",
    "    pd.DataFrame(casual_values)\n",
    "    .groupby(['model', 'dataset'])\n",
    "    .agg(**agg_dict)\n",
    ")\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84419985",
   "metadata": {},
   "source": [
    "## Анализ покупок для каждой propensity-модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fe89b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:40<00:00, 20.16s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "item_name\n",
       "SNACK CAKE - MULTI PACK           46210\n",
       "ANTI-ACIDS                        41225\n",
       "CONTINUITY: FRAMES                36481\n",
       "DIET CNTRL BARS NUTRITIONAL       34985\n",
       "CANDY BARS (SINGLES)(INCLUDING    34078\n",
       "SEASONAL                          33747\n",
       "FRESH                             31949\n",
       "FRZN BREADED PREPARED CHICK       26998\n",
       "STIR FRY/STRIPS/FAJITAS           25245\n",
       "BREAD:ITALIAN/FRENCH              24863\n",
       "Name: idx_item, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def guess_items_map_path(dataset_name: str, base_dir=\"data/preprocessed\",\n",
    "                         min_user=10, min_item=10, min_user_tr=1, min_item_tr=1,\n",
    "                         rec_type=\"mailer\"):\n",
    "    \"\"\"\n",
    "    Пытаемся угадать, где лежит items_map.csv.\n",
    "    Для категорийного уровня (CP/CO) это dunn_cat_..., для продуктового — dunn_...\n",
    "    \"\"\"\n",
    "    cat_dir = os.path.join(base_dir, f\"dunn_cat_{rec_type}_{min_user}_{min_item}_{min_user_tr}_{min_item_tr}\")\n",
    "    prod_dir = os.path.join(base_dir, f\"dunn_{rec_type}_{min_user}_{min_item}_{min_user_tr}_{min_item_tr}\")\n",
    "\n",
    "    candidates = [\n",
    "        os.path.join(cat_dir, \"items_map.csv\"),\n",
    "        os.path.join(prod_dir, \"items_map.csv\"),\n",
    "    ]\n",
    "    for p in candidates:\n",
    "        if os.path.exists(p):\n",
    "            return p\n",
    "    raise FileNotFoundError(f\"Не найден items_map.csv ни в {candidates}\")\n",
    "\n",
    "def attach_item_names(split_df: pd.DataFrame, item_map: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Добавляет к df колонки из item_map по idx_item.\n",
    "    Возвращает НОВЫЙ датафрейм (оригинал не мутируется).\n",
    "    \"\"\"\n",
    "    cols_to_keep = [c for c in item_map.columns if c in\n",
    "                    [\"idx_item\", \"item_id\", \"SUB_COMMODITY_DESC\", \"COMMODITY_DESC\",\n",
    "                     \"BRAND\", \"MANUFACTURER\", \"DEPARTMENT\", \"CURR_SIZE_OF_PRODUCT\"]]\n",
    "    m = item_map[cols_to_keep].copy()\n",
    "\n",
    "    out = split_df.merge(m, on=\"idx_item\", how=\"left\")\n",
    "\n",
    "    # Удобное читабельное поле: для категорий берём SUB_COMMODITY_DESC,\n",
    "    # при её отсутствии — COMMODITY_DESC; (на продуктовом уровне тоже ок — оба поля есть)\n",
    "    if \"SUB_COMMODITY_DESC\" in out.columns and \"COMMODITY_DESC\" in out.columns:\n",
    "        out[\"item_name\"] = out[\"SUB_COMMODITY_DESC\"].fillna(out[\"COMMODITY_DESC\"])\n",
    "    elif \"COMMODITY_DESC\" in out.columns:\n",
    "        out[\"item_name\"] = out[\"COMMODITY_DESC\"]\n",
    "    else:\n",
    "        # самый минимум — вернуть item_id как имя\n",
    "        out[\"item_name\"] = out.get(\"item_id\", out[\"idx_item\"].astype(str))\n",
    "\n",
    "    return out\n",
    "\n",
    "# === основной цикл загрузки и обогащения ===\n",
    "DATASETS = [\"CO\", \"CP\"]\n",
    "all_datasets = {}\n",
    "\n",
    "for name in tqdm(DATASETS):\n",
    "    train_df, vali_df, test_df, num_users, num_items, item_pop = get_dataset(name, path_to_data=\".\")\n",
    "\n",
    "    items_map_path = guess_items_map_path(name)            # можно явно подать base_dir/параметры, если отличались\n",
    "    item_map = pd.read_csv(items_map_path)\n",
    "\n",
    "    # приведём тип индекса к int (на всякий случай)\n",
    "    if item_map[\"idx_item\"].dtype != \"int64\":\n",
    "        item_map[\"idx_item\"] = item_map[\"idx_item\"].astype(\"int64\")\n",
    "\n",
    "    train_named = attach_item_names(train_df, item_map)\n",
    "    vali_named  = attach_item_names(vali_df,  item_map)\n",
    "    test_named  = attach_item_names(test_df,  item_map)\n",
    "\n",
    "    all_datasets[name] = {\n",
    "        \"train\": train_named,\n",
    "        \"vali\": vali_named,\n",
    "        \"test\": test_named,\n",
    "        \"num_users\": num_users,\n",
    "        \"num_items\": num_items,\n",
    "        \"item_popularity\": item_pop,\n",
    "        \"item_map\": item_map,   # чтобы было под рукой\n",
    "    }\n",
    "\n",
    "# Пример: посмотреть топ-10 популярных по названию в CP\n",
    "(all_datasets[\"CP\"][\"train\"]\n",
    " .groupby(\"item_name\")[\"idx_item\"]\n",
    " .count()\n",
    " .sort_values(ascending=False)\n",
    " .head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae3a36d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gt  = DLCE.load_model(dir_path=f\"saved_models/dlce/best_CP\", model_name=f\"model_{1}\", device='cuda')\n",
    "model_pop  = DLCE.load_model(dir_path=f\"saved_models/dlce/best_propcare_CP\", model_name=f\"model_{1}\", device='cuda')\n",
    "model_pc = DLCE.load_model(dir_path=f\"saved_models/dlce/best_popular_CP\", model_name=f\"model_{1}\", device='cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bf8d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DLCE (ground-truth prop.)</th>\n",
       "      <th>DLCE (PropCare prop.)</th>\n",
       "      <th>DLCE (Popularity prop.)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAN DOG FOOD (SKIPPY/PEDIGREE/</td>\n",
       "      <td>‡🛒 SEASONAL</td>\n",
       "      <td>CORN WHITE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WILD BIRD SEED</td>\n",
       "      <td>¶ PAPERBACK BEST SELLER</td>\n",
       "      <td>WILD BIRD SEED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>🛒 SEASONAL</td>\n",
       "      <td>BREAD:PITA/POCKET BREADS</td>\n",
       "      <td>GRAHAM CRACKERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‡🛒 SEASONAL</td>\n",
       "      <td>DOG TREATS (SOFT TREATS)</td>\n",
       "      <td>‡🛒 SEASONAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‡🛒 BABY SPRING WATERS</td>\n",
       "      <td>🛒 BEDDING ACCESSORIES</td>\n",
       "      <td>¶ VENDING SIZE/SNGL SERVE CRACKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CHARCOAL</td>\n",
       "      <td>‡🛒 ANTI-ACIDS</td>\n",
       "      <td>PACKAGE DINNERS: OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>‡🛒 FRESH</td>\n",
       "      <td>PACKAGE DINNERS: OTHER</td>\n",
       "      <td>‡🛒 ANTI-ACIDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SEASONAL CANDY BOX NON-CHOCOLA</td>\n",
       "      <td>GLASS BAKEWARE</td>\n",
       "      <td>DIPILATORIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BREAD:PITA/POCKET BREADS</td>\n",
       "      <td>¶ VENDING SIZE/SNGL SERVE CRACKE</td>\n",
       "      <td>ASEPTIC PACK JUICE AND DRINKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>¶ APPLES GRANNY SMITH (BULK&amp;BAG)</td>\n",
       "      <td>‡🛒 BABY SPRING WATERS</td>\n",
       "      <td>¶ PREMIUM BREAD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DLCE (ground-truth prop.)             DLCE (PropCare prop.)  \\\n",
       "0    CAN DOG FOOD (SKIPPY/PEDIGREE/                       ‡🛒 SEASONAL   \n",
       "1                    WILD BIRD SEED           ¶ PAPERBACK BEST SELLER   \n",
       "2                        🛒 SEASONAL          BREAD:PITA/POCKET BREADS   \n",
       "3                       ‡🛒 SEASONAL          DOG TREATS (SOFT TREATS)   \n",
       "4             ‡🛒 BABY SPRING WATERS             🛒 BEDDING ACCESSORIES   \n",
       "5                          CHARCOAL                     ‡🛒 ANTI-ACIDS   \n",
       "6                          ‡🛒 FRESH            PACKAGE DINNERS: OTHER   \n",
       "7    SEASONAL CANDY BOX NON-CHOCOLA                    GLASS BAKEWARE   \n",
       "8          BREAD:PITA/POCKET BREADS  ¶ VENDING SIZE/SNGL SERVE CRACKE   \n",
       "9  ¶ APPLES GRANNY SMITH (BULK&BAG)             ‡🛒 BABY SPRING WATERS   \n",
       "\n",
       "            DLCE (Popularity prop.)  \n",
       "0                        CORN WHITE  \n",
       "1                    WILD BIRD SEED  \n",
       "2                   GRAHAM CRACKERS  \n",
       "3                       ‡🛒 SEASONAL  \n",
       "4  ¶ VENDING SIZE/SNGL SERVE CRACKE  \n",
       "5            PACKAGE DINNERS: OTHER  \n",
       "6                     ‡🛒 ANTI-ACIDS  \n",
       "7                      DIPILATORIES  \n",
       "8     ASEPTIC PACK JUICE AND DRINKS  \n",
       "9                   ¶ PREMIUM BREAD  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "USER_ID = 238\n",
    "TOPK = 10\n",
    "\n",
    "# 1) берём тест и мапу названий\n",
    "test = all_datasets['CP']['test'].copy()\n",
    "item_map = all_datasets['CP']['item_map'].copy()\n",
    "\n",
    "# 2) считаем скоры трёх моделей\n",
    "test_user = test[test['idx_user'] == USER_ID].copy()\n",
    "\n",
    "\n",
    "test_user['score_gt']  = model_gt.predict(test_user)\n",
    "test_user['score_pop'] = model_pop.predict(test_user)\n",
    "test_user['score_pc']  = model_pc.predict(test_user)\n",
    "\n",
    "test_user = test_user[test_user['idx_time'] == 9]\n",
    "\n",
    "# 3) агрегируем по товару, чтобы корректно рисовать иконки\n",
    "agg = (test_user\n",
    "       .groupby(['idx_item','item_name'], as_index=False)\n",
    "       .agg(outcome_any=('outcome', lambda x: int(np.max(x) > 0)),\n",
    "            treated_any=('treated', 'max'),\n",
    "            causal_sign=('causal_effect', 'max') ,  # -1,0,1\n",
    "            score_gt=('score_gt','max'),\n",
    "            score_pop=('score_pop','max'),\n",
    "            score_pc=('score_pc','max'))\n",
    "      )\n",
    "\n",
    "def make_icon_row(row):\n",
    "    icons = []\n",
    "    if row['causal_sign'] == 1:  icons.append('‡')\n",
    "    elif row['causal_sign'] == -1: icons.append('¶')\n",
    "    # if row['treated_any'] == 1: icons.append('📬')\n",
    "    if row['outcome_any'] == 1: icons.append('🛒')\n",
    "    return ''.join(icons)\n",
    "\n",
    "agg['icons'] = agg.apply(make_icon_row, axis=1)\n",
    "\n",
    "def topk_strings(df, score_col, k=TOPK):\n",
    "    part = df.sort_values(score_col, ascending=False).head(k).copy()\n",
    "\n",
    "    return [f\"{r.icons} {r.item_name}\".strip()\n",
    "            for _, r in part.iterrows()]\n",
    "\n",
    "col_gt  = topk_strings(agg, 'score_gt',  TOPK)\n",
    "col_pop = topk_strings(agg, 'score_pop', TOPK)\n",
    "col_pc  = topk_strings(agg, 'score_pc',  TOPK)\n",
    "\n",
    "def pad(lst, k):\n",
    "    return lst + ['']*(k-len(lst))\n",
    "table = pd.DataFrame({\n",
    "    'DLCE (ground-truth prop.)': pad(col_gt, TOPK),\n",
    "    'DLCE (PropCare prop.)'    : pad(col_pop, TOPK),\n",
    "    'DLCE (Popularity prop.)'  : pad(col_pc, TOPK),\n",
    "})\n",
    "\n",
    "from IPython.display import display\n",
    "display(table)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "casual10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
